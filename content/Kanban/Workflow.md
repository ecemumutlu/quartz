---

kanban-plugin: board

---

## Inactive

- [ ] deepmind rl dersi #low
- [ ] Intro to DL book #ask
- [ ] [Building with Instruction-Tuned LLMs: A Step-by-Step Guide](https://www.youtube.com/watch?v=eTieetk2dSw)
- [ ] [[5-lms_are_unsupervised_multitask_learners.pdf]]
- [ ] Tensorflow Neural Machine Translation (seq2seq) Tutorial #ask
- [ ] [Topic 4: What is JEPA?](https://www.turingpost.com/p/jepa)
- [ ] [[13-llama3.pdf | Llama-3 ]] oku
- [ ] Skim through [[8-LayerNormalizationInTheTransformer.pdf|layer norm]]


## Reading List

- [ ] [[18-PruningAndDistillation .pdf |Pruning and Distillation]]
- [ ] [[19-LLM Pruning and Distillation in Practice.pdf|LLM Pruning and Distillation in Practice]] from NVIDIA
- [ ] [Knowledge Distillation Blogpost](https://towardsdatascience.com/knowledge-distillation-simplified-dd4973dbc764) from Towards Data Science
- [ ] [Deep Learning — Model Optimization and Compression: Simplified Blogpost](https://towardsdatascience.com/machine-learning-models-compression-and-quantization-simplified-a302ddf326f2) by Towards data science
- [ ] [Everything You Need To Know About Knowledge Distillation, aka Teacher-Student Model Blogpost](https://amit-s.medium.com/everything-you-need-to-know-about-knowledge-distillation-aka-teacher-student-model-d6ee10fe7276)
- [ ] 


## To do

- [ ] semantic textual similarity sentence transformers baştan sona train et
- [ ] deep metric learning ve metric learning araştır #meetingNotes
- [ ] multilingual sentence transformers modelleri ile de inference denenebilir


## Done

- [ ] https://www.youtube.com/watch?v=TIqf4LMNCjU


## To be planned

- [ ] llama3
- [ ] llama.cpp ve llama.cpp-python kütüphaneleri incelensin
- [ ] llama.cpp ve gguf formatlarını incele
- [ ] quantization araştırması - lmstudio


***

## Archive

- [ ] Jalammar [attention](https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/)
- [ ] RNN Intro [Video](https://www.youtube.com/watch?v=UNmqTiOnRfg)
- [ ] [Jalammar transformers](https://jalammar.github.io/illustrated-transformer/)
- [ ] Attention is all you need
- [ ] Coursera find a course #ask
- [ ] Coursera module-1 week-2
- [ ] [[2-llama1.pdf|Llama-1]]
- [ ] Coursera DLS module1 week3
- [ ] Byte-pair encoding: https://www.geeksforgeeks.org/byte-pair-encoding-bpe-in-nlp/
- [ ] Llama1 summary
- [ ] [Llama2 related GQA](https://medium.com/@raisomya360/demystifying-sliding-window-grouped-query-attention-a-simpler-approach-to-efficient-neural-6fb03b7d021f)
- [ ] module1 week3 [assignment](https://github.com/abdur75648/Deep-Learning-Specialization-Coursera/blob/main/Neural%20Networks%20and%20Deep%20Learning/Week3/Planar%20data%20classification%20with%20one%20hidden%20layer/Planar_data_classification_with_onehidden_layer_v6c.ipynb) inceleme
- [ ] Coursera DLS module1 week4
- [ ] IBM LLama2 [blogpost](https://www.ibm.com/topics/llama-2)
- [ ] Coursera DLS module1 week4 assignment
- [ ] Coursera DLS module2 week1
- [ ] [[3-llama2.pdf|Llama-2]]
- [ ] Llama2 summary
- [ ] [Sentence Transformers](https://osanseviero.github.io/hackerllama/blog/posts/sentence_embeddings/#sentence-transformers) #meetingNotes
- [ ] inference denemek için küçük bir dataseti oluştur
- [ ] türkçe dataseti bul #meetingNotes
- [ ] türkçe sentence transformers inference dene
- [ ] ssh configs
- [ ] RAG işleme yapılarına bak #meetingNotes
- [ ] micro editor
- [ ] Coursera DLS module2 week2
- [ ] [Training and Finetuning Embedding Models with Sentence Transformers v3](https://huggingface.co/blog/train-sentence-transformers) #meetingNotes
- [ ] [Building LLM Applications: Introduction (Part 1)](https://medium.com/@vipra_singh/building-llm-applications-introduction-part-1-1c90294b155b#4d28) #meetingNotes
- [ ] RAG [videosu](https://www.youtube.com/watch?v=tcqEUSNCn8I) izlendi
- [ ] coursera dls module2 week3
- [ ] ml lifecycle problemi üzerine düşün
- [ ] dls module2 week1 assignment
- [ ] ["bi-encoder" ve "cross-encoder" ](https://www.sbert.net/examples/applications/cross-encoder/README.html)kavramları.
- [ ] ML Döngüsü Nedir ve Ne Yapıyoruz? #educationalMeeting
- [ ] sentence transformer eğitmek için kullanılmış bir dataset bul #meetingNotes şu formatta kulllanıldı, böyle böyle bir şeymiş vs, türkçe dataset bulamayabilirsin şimdilik ingilizce de bakabilrisin
- [ ] rag blogpost part 5
- [ ] advanced python kursu
- [ ] [[14-bert.pdf| BERT]] paper tekrar oku #order1
- [ ] [bi-encoder ve cross-encoder](https://osanseviero.github.io/hackerllama/blog/posts/sentence_embeddings2/) yapılarını architectural incele #meetingNotes
- [ ] sonra sentence bert oku #order2 [link1](https://medium.com/towards-data-science/sbert-deb3d4aef8a4) [[15-sbert.pdf|link2]]
- [ ] [[12-textual-sim-paper.pdf | textual similarity paper]] oku (GTE paper) #order3
- [ ] sentence bert [blogpost](https://towardsdatascience.com/sbert-deb3d4aef8a4)
- [ ] codebase i conda environment ına çevir
- [ ] embedding modellerine ve bu modeller nasıl ve ne gibi bir veriset ile train/finetune oluyor konularına da bakabilirsin #meetingNotes
- [ ] contrastive learning araştır #meetingNotes
- [ ] coursera dls module 2 week3 assignment
- [ ] kodları snorlax formatına çevir
- [ ] self-attention yapısına bakabilirsin multihead #meetingNotes

%% kanban:settings
```
{"kanban-plugin":"board","list-collapse":[false,false,false,false,false]}
```
%%